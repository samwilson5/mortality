{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Load in the drone image as well as the image with classification data. The classification image was created at a higher resolution, so it needs to be downscaled prior to classification\n",
        "\n",
        "-Note: visualization is currently commented out because it takes a long time and isn't necassary"
      ],
      "metadata": {
        "id": "jMJvZhURe4gf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpJvKtOm32v0"
      },
      "outputs": [],
      "source": [
        "#import Python 3's print function and division\n",
        "from __future__ import print_function, division\n",
        "\n",
        "#Import GDAL, NumPy, and matplotlib\n",
        "from osgeo import gdal,gdal_array\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import LeaveOneOut, KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "#Tell GDAL to throw Python exceptions and register all drivers\n",
        "gdal.UseExceptions()\n",
        "gdal.AllRegister()\n",
        "\n",
        "#read in our image and ROI image\n",
        "img_ds= gdal.Open(\"\",\n",
        "                gdal.GA_ReadOnly)\n",
        "roi_ds = gdal.Open('')\n",
        "\n",
        "# Need resolutions to match\n",
        "img_reference = img_ds.GetGeoTransform()\n",
        "x_res = img_reference[1]\n",
        "y_res = -img_reference[5]\n",
        "minx = img_reference[0]\n",
        "maxy = img_reference[3]\n",
        "\n",
        "input = roi_ds\n",
        "# This line allows us to output the image and use transformation to do the lifting of reprojection\n",
        "output = ''\n",
        "kwargs = {'format':'GTiff', 'xRes': x_res, 'yRes':y_res}\n",
        "ds = gdal.Warp(output, input, **kwargs)\n",
        "\n",
        "# Now read in that newly reprojected image\n",
        "roi_ds = gdal.Open('/content/drive/MyDrive/Drone_Flights/Classification/NV_2_2_class/NV_02_02_trainingReady4.tif')\n",
        "\n",
        "\n",
        "\n",
        "img = np.zeros((img_ds.RasterYSize, img_ds.RasterXSize,img_ds.RasterCount),\n",
        "               gdal_array.GDALTypeCodeToNumericTypeCode(img_ds.GetRasterBand(1).DataType))\n",
        "for b in range(3):\n",
        "  img[:,:,b] = img_ds.GetRasterBand(b+1).ReadAsArray()\n",
        "\n",
        "roi = roi_ds.GetRasterBand(1).ReadAsArray().astype(np.float64)\n",
        "\n",
        "# Display them\n",
        "#plt.subplot(121)\n",
        "#plt.imshow(img[:,:,1],cmap=plt.cm.Greys_r)\n",
        "#plt.title('Red')\n",
        "\n",
        "#plt.subplot(122)\n",
        "#plt.imshow(roi, cmap=plt.cm.Spectral)\n",
        "#plt.title('ROI Training Data')\n",
        "\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the event of wanting to save the images as numpy arrays, use the code chunk below (use extention .npy)"
      ],
      "metadata": {
        "id": "Pupb4qoUfL9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#np.save('',img)\n",
        "#np.save('',roi)"
      ],
      "metadata": {
        "id": "Lus674Ud3S_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the event of wanting to open images from numpy arrays, use the code chunk below (use extension .npy)\n",
        "\n",
        "'r+' allows for reading in memory map mode to save ram"
      ],
      "metadata": {
        "id": "EiblzX9nfQUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "img = np.load('',mmap_mode='r+')\n",
        "roi = np.load('')"
      ],
      "metadata": {
        "id": "Eyvf4XL84q0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print how many training pixels we have"
      ],
      "metadata": {
        "id": "bNnb37IkfT8l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z450sV4TZKk-"
      },
      "outputs": [],
      "source": [
        "# Find how many non-zero entries we have-- ie how many training\n",
        "# data samples\n",
        "n_samples = (roi > 0 ).sum()\n",
        "print('We have {n} samples'.format(n=n_samples))\n",
        "\n",
        "# What are our classificaitn labels?\n",
        "labels = np.unique(roi[roi > 0])\n",
        "print(\"The training data includes {n} classes:{classes}\"\n",
        ".format(n=labels.size, classes = labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select areas within our image that we have classifications for"
      ],
      "metadata": {
        "id": "bcRQrDhnfXJX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrIV85xyaGaK"
      },
      "outputs": [],
      "source": [
        "# We will need a \"X\" matrix containing our features, and a \"y\" array containing our labels\n",
        "#     These will have n_samples rows\n",
        "\n",
        "x = img[roi > 0, :]\n",
        "y = roi[roi > 0]\n",
        "\n",
        "print('Our X matrix is sized: {sz}'.format(sz=x.shape))\n",
        "print('Our Y array is sized: {sz}'.format(sz=y.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store classification labels"
      ],
      "metadata": {
        "id": "GCGobIKB83_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_labels = np.unique(y_test)"
      ],
      "metadata": {
        "id": "Og7MBvfAlUvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the data in two dimensions to understand how well classificaiton might work for this dataset"
      ],
      "metadata": {
        "id": "yn3AsuQr898N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "colors = ['red', 'blue', 'green']\n",
        "for c in np.arange(3):\n",
        "    mask = (y_test==(c+1))\n",
        "    plt.scatter(x_test[mask,1], x_test[mask,2], color=colors[c], label=y_labels[c])\n",
        "\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hL-p3Ewykv2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I also like to test out how the data looks in the first two principal components to see if seperation might make more sense in these dimensions"
      ],
      "metadata": {
        "id": "Pe1iH7579EHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "X = x_test - np.mean(x_test,0)\n",
        "pca = PCA()\n",
        "pca.fit(X)\n",
        "pcs = pca.fit_transform(X)\n",
        "\n",
        "\n",
        "pv1 = pca.components_[0]\n",
        "pv2 = pca.components_[1]\n",
        "pcs = pca.fit_transform(X)[:,0:2]\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "colors = ['red', 'blue', 'green']\n",
        "for i in np.arange(3):\n",
        "    mask = y_test==i+1\n",
        "    ax.scatter(pcs[mask,0], pcs[mask,1], alpha=0.8, c=colors[i], label=y_labels[i])\n",
        "plt.legend(loc='upper right')\n",
        "plt.xlabel('principal component 1')\n",
        "plt.ylabel('principal component 2')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tAVdiuGXou5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build my classification tree"
      ],
      "metadata": {
        "id": "mLaMlyRE9aKT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXBgfZATjPKt"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import LeaveOneOut, KFold\n",
        "\n",
        "tree=RandomForestClassifier(n_estimators=100,max_depth=10,oob_score=True,verbose=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit classification to training data"
      ],
      "metadata": {
        "id": "w9PPlBUF9czq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POSHOEWGsMVt"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
        "rf = tree.fit(x,y)\n",
        "y_pred = rf.predict(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the classification tree"
      ],
      "metadata": {
        "id": "1UOmABmj9vrL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzyMkUcqshIJ"
      },
      "outputs": [],
      "source": [
        "# Tree Visualisation\n",
        "from sklearn.tree import export_graphviz\n",
        "from IPython.display import Image\n",
        "import graphviz\n",
        "for i in range(3):\n",
        "    tree = rf.estimators_[i]\n",
        "    dot_data = export_graphviz(tree,\n",
        "                               filled=True,\n",
        "                               max_depth=6,\n",
        "                               impurity=False,\n",
        "                               proportion=True)\n",
        "    graph = graphviz.Source(dot_data)\n",
        "    display(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion matrices can be really helpful for seeing where the model might have shortcomings"
      ],
      "metadata": {
        "id": "DMyXjkdL9zkt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPSTohgBta6j"
      },
      "outputs": [],
      "source": [
        "# Create the confusion matrix\n",
        "cm = confusion_matrix(y, y_pred)\n",
        "\n",
        "ConfusionMatrixDisplay(confusion_matrix=cm).plot();"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "View the out-of-bad predicition accuracy"
      ],
      "metadata": {
        "id": "MFcwYzVZ-GTc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBYq8UXIjhBu"
      },
      "outputs": [],
      "source": [
        "print('Our OOB prediction accuracy is : {oob}%'.format(\n",
        "    oob=rf.oob_score_ * 100\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "View the importance of the input bands"
      ],
      "metadata": {
        "id": "CEdji5Ng-Jiy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4cWoY6Aomqk"
      },
      "outputs": [],
      "source": [
        "bands =  [1,2,3]\n",
        "\n",
        "for b, imp in zip(bands, rf.feature_importances_):\n",
        "  print('Band {b} importance: {imp}'.format(b=b, imp=imp))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR3WToLro4qT"
      },
      "source": [
        "**Predict the rest of the image**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33hHSH1Io7X6"
      },
      "outputs": [],
      "source": [
        "# Take our full image, and reshape into long 2d array\n",
        "# for classificaiton\n",
        "new_shape = (img.shape[0] * img.shape[1], img.shape[2])\n",
        "\n",
        "img_as_array = img[:,:,:4].reshape(new_shape)\n",
        "print('Reshaped from {o} to {n}'.format(o=img.shape,\n",
        "                                        n=img_as_array.shape))\n",
        "\n",
        "# Now predict for each pixel\n",
        "class_prediction = rf.predict(img_as_array)\n",
        "\n",
        "# Reshape our classification map\n",
        "class_prediction = class_prediction.reshape(img[:, :, 0].shape)\n",
        "print('Reshaped from {o} to {n}'.format(o=img.shape,\n",
        "                                        n=class_prediction.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAsbcgalqb4c"
      },
      "source": [
        "**Visualize**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNDJjhJtr8Mr"
      },
      "outputs": [],
      "source": [
        "n = class_prediction.max()\n",
        "#Setup colormap\n",
        "colors = dict((\n",
        "    (0, (0,0,0,255)),\n",
        "    (1, (0,150,0,255)), #dead sage\n",
        "    (2, (0,0,255,255)), #green plants\n",
        "    (3, (0,255,0,255))#dead others and soil\n",
        "))\n",
        "\n",
        "#Put 0 - 255 as float 0 -1\n",
        "for k in colors:\n",
        "    v = colors[k]\n",
        "    v = [_v / 255.0 for _v in v]\n",
        "    colors[k] = v\n",
        "\n",
        "index_colors = [colors[key] if key in colors else\n",
        "                (255, 255, 255, 0) for key in range(1, n + 1)]\n",
        "cmap = plt.matplotlib.colors.ListedColormap(index_colors, 'Classification', n)\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.imshow(class_prediction, cmap=cmap, interpolation='none')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export the classified image as a tif file to Google Drive"
      ],
      "metadata": {
        "id": "BJzQpY4mbAv3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqOoQgiqw5fq"
      },
      "outputs": [],
      "source": [
        "# create the output image\n",
        "driver = img_ds.GetDriver()\n",
        "outDs = driver.Create(\"\", img_ds.RasterXSize, img_ds.RasterYSize, 1, gdal.GDT_Float32)\n",
        "outBand = outDs.GetRasterBand(1)\n",
        "outBand.SetNoDataValue(15)\n",
        "outBand.WriteArray(class_prediction)\n",
        "outDs.SetGeoTransform(img_ds.GetGeoTransform())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}